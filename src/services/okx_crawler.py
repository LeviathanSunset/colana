#!/usr/bin/env python3
"""
ç®€åŒ–çš„OKX Web3çˆ¬è™« - ä¸“é—¨ä¸ºTelegram Botä½¿ç”¨
åªè·å–å¤§æˆ·æŒæœ‰çš„ä»£å¸æ’è¡Œæ¦œ
"""

import requests
import json
import time
import random
import os
from datetime import datetime
from typing import List, Dict, Optional
from ..utils.data_manager import DataManager

# å…¨å±€åˆ†æç¼“å­˜ï¼Œç”¨äºå­˜å‚¨åˆ†æç»“æœä»¥ä¾›æŒ‰é’®å›è°ƒä½¿ç”¨
analysis_cache = {}


class OKXCrawlerForBot:
    """
    ç®€åŒ–çš„OKX Web3çˆ¬è™« - ä¸“é—¨ä¸ºBotä½¿ç”¨
    åªå…³æ³¨è·å–å¤§æˆ·æŒæœ‰çš„ä»£å¸ç»Ÿè®¡ä¿¡æ¯
    """

    def __init__(self):
        """åˆå§‹åŒ–çˆ¬è™«"""
        self.session = requests.Session()

        # åŸºç¡€è¯·æ±‚å¤´ - æ¨¡æ‹ŸçœŸå®æµè§ˆå™¨
        self.headers = {
            "accept": "application/json",
            "accept-encoding": "gzip, deflate, br, zstd",
            "accept-language": "en-US,en;q=0.9,zh-HK;q=0.8,zh-CN;q=0.7,zh;q=0.6,es-MX;q=0.5,es;q=0.4,ru-RU;q=0.3,ru;q=0.2",
            "app-type": "web",
            "cache-control": "no-cache",
            "dnt": "1",
            "pragma": "no-cache",
            "priority": "u=1, i",
            "sec-ch-ua": '"Chromium";v="130", "Google Chrome";v="130", "Not?A_Brand";v="99"',
            "sec-ch-ua-mobile": "?0",
            "sec-ch-ua-platform": '"Windows"',
            "sec-fetch-dest": "empty",
            "sec-fetch-mode": "cors",
            "sec-fetch-site": "same-origin",
            "user-agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36",
            "x-cdn": "https://web3.okx.com",
        }

        # ç¡®ä¿æ—¥å¿—ç›®å½•å­˜åœ¨
        self.data_manager = DataManager()
        self.log_dir = self.data_manager.get_file_path("logs", "okx_crawler.log").parent

    def log_info(self, message):
        """è®°å½•ä¿¡æ¯åˆ°æ—¥å¿—æ–‡ä»¶"""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        log_message = f"[{timestamp}] {message}\n"

        # å†™å…¥åˆ°æ—¥å¿—æ–‡ä»¶
        log_file = os.path.join(
            self.log_dir, f"okx_crawler_{datetime.now().strftime('%Y%m%d')}.log"
        )
        with open(log_file, "a", encoding="utf-8") as f:
            f.write(log_message)

        # ä¹Ÿæ‰“å°åˆ°æ§åˆ¶å°
        print(f"[OKX] {message}")

    def get_token_holders(
        self, token_address: str, chain_id: str = "501", max_retries: int = 3
    ) -> List[Dict]:
        """
        è·å–ä»£å¸æŒæœ‰è€…æ’è¡Œæ¦œ
        """
        self.log_info(f"å¼€å§‹è·å–ä»£å¸æŒæœ‰è€…: {token_address}")

        for attempt in range(1, max_retries + 1):
            if attempt > 1:
                self.log_info(f"é‡è¯•è·å–æŒæœ‰è€…ä¿¡æ¯... (å°è¯• {attempt}/{max_retries})")

            current_timestamp = str(int(time.time() * 1000))

            url = "https://web3.okx.com/priapi/v1/dx/market/v2/holders/ranking-list"
            params = {
                "chainId": chain_id,
                "tokenAddress": token_address,
                "currentUserWalletAddress": "0xa6b67e6f61dba6363b36bbcef80d971a6d1f0ce5",
                "t": current_timestamp,
            }

            # åˆå¹¶çœŸå®è¯·æ±‚å¤´
            headers = self.headers.copy()
            headers.update(
                {
                    "cookie": 'devId=31011088-da0a-4bd8-8f3d-9731400b5208; locale=en_US; _monitor_extras={"deviceId":"uC3r8hJBpqO__FJ2_Z2NMj","eventId":106,"sequenceNumber":106}',
                    "devid": "31011088-da0a-4bd8-8f3d-9731400b5208",
                    "x-request-timestamp": current_timestamp,
                    "referer": f"https://web3.okx.com/token/solana/{token_address}",
                }
            )

            try:
                response = self.session.get(url, params=params, headers=headers, timeout=30)

                if response.status_code == 200:
                    try:
                        data = response.json()

                        # ä¿å­˜åŸå§‹çš„holderRankingListæ•°æ®åˆ°æ—¥å¿—æ–‡ä»¶
                        if data.get("code") == 0:
                            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                            raw_data_file = self.data_manager.get_file_path(
                                "holders", f"holders_raw_{token_address}_{timestamp}.json"
                            )
                            with open(raw_data_file, "w", encoding="utf-8") as f:
                                json.dump(data, f, ensure_ascii=False, indent=2)
                            self.log_info(f"åŸå§‹æŒæœ‰è€…æ•°æ®å·²ä¿å­˜åˆ°: {raw_data_file}")

                        if data.get("code") == 0:
                            holders_data = data.get("data", {})

                            # å°è¯•ä¸åŒçš„æ•°æ®è·¯å¾„
                            holders = []
                            if isinstance(holders_data, dict):
                                # å°è¯•å¤šä¸ªå¯èƒ½çš„é”®å
                                possible_keys = [
                                    "holderRankingList",
                                    "data",
                                    "holders",
                                    "list",
                                    "ranking",
                                ]
                                for key in possible_keys:
                                    if key in holders_data and isinstance(holders_data[key], list):
                                        holders = holders_data[key]
                                        break

                            if holders:
                                self.log_info(f"æˆåŠŸè·å–åˆ° {len(holders)} ä¸ªæŒæœ‰è€…")
                                # ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„æ•°é‡è®¾ç½®
                                try:
                                    from ..core.config import get_config

                                    config = get_config()
                                    return holders[: config.analysis.top_holders_count]
                                except ImportError:
                                    return holders[:20]  # å›é€€åˆ°é»˜è®¤å€¼
                            else:
                                self.log_info("æœªæ‰¾åˆ°æŒæœ‰è€…æ•°æ®")
                                return []
                        else:
                            self.log_info(f"APIè¿”å›é”™è¯¯: {data.get('msg', 'æœªçŸ¥é”™è¯¯')}")

                    except json.JSONDecodeError as e:
                        self.log_info(f"JSONè§£æå¤±è´¥: {str(e)}")

                else:
                    self.log_info(f"HTTPé”™è¯¯ {response.status_code}")

                # æ ¹æ®çŠ¶æ€ç å†³å®šæ˜¯å¦é‡è¯•
                if response.status_code in [429, 500, 502, 503, 504]:
                    if attempt < max_retries:
                        delay = random.uniform(2, 5)
                        self.log_info(f"ç­‰å¾… {delay:.1f} ç§’åé‡è¯•...")
                        time.sleep(delay)
                        continue

                break

            except requests.exceptions.RequestException as e:
                self.log_info(f"è¯·æ±‚å¼‚å¸¸: {str(e)}")
                if attempt < max_retries:
                    delay = random.uniform(2, 5)
                    self.log_info(f"ç­‰å¾… {delay:.1f} ç§’åé‡è¯•...")
                    time.sleep(delay)
                    continue
                else:
                    break

        self.log_info("è·å–æŒæœ‰è€…ä¿¡æ¯å¤±è´¥")
        return []

    def get_wallet_assets(self, wallet_address: str) -> Dict:
        """
        è·å–é’±åŒ…èµ„äº§ç»„åˆä¿¡æ¯
        """
        self.log_info(f"è·å–é’±åŒ…èµ„äº§: {wallet_address[:8]}...{wallet_address[-6:]}")

        current_timestamp = str(int(time.time() * 1000))

        # æ­£ç¡®çš„POST APIç«¯ç‚¹
        url = "https://web3.okx.com/priapi/v2/wallet/asset/profile/all/explorer"
        params = {"t": current_timestamp}

        payload = {
            "userUniqueId": "",
            "hideValueless": False,
            "address": wallet_address,
            "forceRefresh": True,
            "page": 1,
            "limit": 10,
            "chainIndexes": [],
        }

        headers = self.headers.copy()
        headers.update(
            {
                "content-type": "application/json",
                "content-length": "156",
                "origin": "https://web3.okx.com",
                "referer": f"https://web3.okx.com/portfolio/{wallet_address}",
                "x-request-timestamp": current_timestamp,
                # ä½¿ç”¨åŸºç¡€çš„è®¤è¯å¤´
                "device-token": "01980a38-038a-44d9-8da3-a8276bbcb5b9",
                "devid": "01980a38-038a-44d9-8da3-a8276bbcb5b9",
                "platform": "web",
                "x-locale": "en_US",
                "x-utc": "0",
                "x-zkdex-env": "0",
            }
        )

        # ç®€åŒ–çš„cookie
        cookie_str = "devId=01980a38-038a-44d9-8da3-a8276bbcb5b9; locale=en_US"
        headers["cookie"] = cookie_str

        try:
            response = self.session.post(
                url, params=params, json=payload, headers=headers, timeout=30
            )

            if response.status_code == 200:
                try:
                    data = response.json()

                    if data.get("code") == 0:
                        assets_data = data.get("data", {})
                        tokens_info = assets_data.get("tokens", {})
                        token_list = tokens_info.get("tokenlist", [])

                        if token_list:
                            # è®¡ç®—æ€»ä»·å€¼
                            total_value = 0
                            for token in token_list:
                                try:
                                    value = float(token.get("currencyAmount", 0) or 0)
                                    total_value += value
                                except (ValueError, TypeError):
                                    continue

                            self.log_info(
                                f"è·å–åˆ°èµ„äº§ä¿¡æ¯: ${total_value:,.2f} (åŒ…å« {len(token_list)} ä¸ªä»£å¸)"
                            )
                        else:
                            self.log_info("æœªæ‰¾åˆ°ä»£å¸åˆ—è¡¨")

                        return assets_data
                    else:
                        self.log_info(f"APIè¿”å›é”™è¯¯: {data.get('msg', 'æœªçŸ¥é”™è¯¯')}")

                except json.JSONDecodeError as e:
                    self.log_info(f"JSONè§£æå¤±è´¥: {str(e)}")
            else:
                self.log_info(f"HTTPé”™è¯¯ {response.status_code}")

        except requests.exceptions.RequestException as e:
            self.log_info(f"è¯·æ±‚å¼‚å¸¸: {str(e)}")

        return {}

    def extract_top_tokens(self, assets_data: Dict) -> List[Dict]:
        """
        ä»èµ„äº§æ•°æ®ä¸­æå–æœ‰ä»·å€¼çš„ä»£å¸
        """
        all_tokens = []

        tokens_info = assets_data.get("tokens", {})
        token_list = tokens_info.get("tokenlist", [])

        if not token_list:
            return []

        for token in token_list:
            try:
                symbol = token.get("symbol", "Unknown")
                name = token.get("name", "Unknown")
                chain = token.get("chainName", "Unknown")

                # ä» coinBalanceDetails ä¸­è·å–åœ°å€ä¿¡æ¯
                balance_details = token.get("coinBalanceDetails", [])
                address = ""
                if balance_details and len(balance_details) > 0:
                    address = balance_details[0].get("address", "")

                # è¿‡æ»¤æ‰SOLä»£å¸ï¼ˆåŸç”Ÿä»£å¸ï¼Œä¸éœ€è¦åˆ†æï¼‰
                if symbol == "SOL":
                    continue

                # æ•°å€¼å­—æ®µè½¬æ¢
                try:
                    balance = float(token.get("coinAmount", "0") or 0)
                    price_usd = float(token.get("coinUnitPrice", "0") or 0)
                    value_usd = float(token.get("currencyAmount", "0") or 0)
                except (ValueError, TypeError):
                    continue

                token_info = {
                    "chain": chain,
                    "symbol": symbol,
                    "name": name,
                    "address": address,
                    "balance": balance,
                    "value_usd": value_usd,
                    "price_usd": price_usd,
                }

                # åªæ·»åŠ æœ‰ä»·å€¼çš„ä»£å¸ï¼ˆæ’é™¤SOLåï¼‰
                if token_info["value_usd"] > 0:
                    all_tokens.append(token_info)

            except Exception:
                continue

        # æŒ‰ä»·å€¼æ’åº
        all_tokens.sort(key=lambda x: x["value_usd"], reverse=True)
        return all_tokens

    def is_excluded_holder(self, holder: Dict) -> bool:
        """
        åˆ¤æ–­æŒæœ‰è€…æ˜¯å¦åº”è¯¥è¢«æ’é™¤ï¼ˆæµåŠ¨æ€§æ± ã€äº¤æ˜“æ‰€ç­‰ï¼‰
        """
        # æ£€æŸ¥ holderTagVO
        holder_tag_vo = holder.get("holderTagVO", {})
        if holder_tag_vo:
            # æ£€æŸ¥æ˜¯å¦ä¸ºæµåŠ¨æ€§æ± 
            if holder_tag_vo.get("liquidityPool") == "1":
                return True
        
        # æ£€æŸ¥ tagList
        tag_list = holder.get("tagList", [])
        for tag in tag_list:
            if isinstance(tag, list) and len(tag) > 0:
                tag_name = tag[0]
                # æ’é™¤æµåŠ¨æ€§æ± å’Œäº¤æ˜“æ‰€
                if tag_name in ["liquidityPool", "exchange"]:
                    return True
        
        # æ£€æŸ¥ userAddressTagVO
        user_address_tag_vo = holder.get("userAddressTagVO", {})
        if "liquidityPool" in user_address_tag_vo or "exchange" in user_address_tag_vo:
            return True
        
        return False

    def analyze_token_holders(self, token_address: str, top_holders_count: int = None) -> Dict:
        """
        åˆ†æä»£å¸å¤§æˆ·å¹¶è¿”å›ä»£å¸ç»Ÿè®¡ä¿¡æ¯
        ä¸“é—¨ä¸ºBotä¼˜åŒ–ï¼Œåªè¿”å›å¿…è¦çš„ä¿¡æ¯
        """
        # å¦‚æœæ²¡æœ‰æä¾›å‚æ•°ï¼Œä»é…ç½®æ–‡ä»¶è·å–
        if top_holders_count is None:
            try:
                from ..core.config import get_config

                config = get_config()
                top_holders_count = config.analysis.top_holders_count
            except ImportError:
                top_holders_count = 20  # å›é€€åˆ°é»˜è®¤å€¼
        self.log_info(f"å¼€å§‹åˆ†æä»£å¸: {token_address}")

        # 1. è·å–æŒæœ‰è€…æ’è¡Œæ¦œ
        holders = self.get_token_holders(token_address)

        if not holders:
            self.log_info("æ— æ³•è·å–æŒæœ‰è€…ä¿¡æ¯")
            return {}

        # è¿‡æ»¤æ‰æµåŠ¨æ€§æ± å’Œäº¤æ˜“æ‰€åœ°å€
        filtered_holders = []
        excluded_count = 0
        
        for holder in holders:
            if self.is_excluded_holder(holder):
                excluded_count += 1
                # è®°å½•è¢«æ’é™¤çš„åœ°å€ä¿¡æ¯
                wallet_address = holder.get("holderWalletAddress", "")
                tag_list = holder.get("tagList", [])
                tag_names = [tag[0] if isinstance(tag, list) and len(tag) > 0 else str(tag) for tag in tag_list]
                self.log_info(f"æ’é™¤åœ°å€: {wallet_address[:8]}...{wallet_address[-6:]} (æ ‡ç­¾: {', '.join(tag_names)})")
            else:
                filtered_holders.append(holder)
        
        self.log_info(f"åŸå§‹æŒæœ‰è€…: {len(holders)} ä¸ªï¼Œæ’é™¤ {excluded_count} ä¸ªæµåŠ¨æ€§æ± /äº¤æ˜“æ‰€åœ°å€ï¼Œå‰©ä½™ {len(filtered_holders)} ä¸ª")

        if not filtered_holders:
            self.log_info("è¿‡æ»¤åæ²¡æœ‰å¯åˆ†æçš„æŒæœ‰è€…")
            return {}

        # 2. åˆ†ææ¯ä¸ªå¤§æˆ·çš„èµ„äº§
        holder_analysis = []

        # ä½¿ç”¨è¿‡æ»¤åçš„æŒæœ‰è€…åˆ—è¡¨ï¼Œå–å‰Nå
        for i, holder in enumerate(filtered_holders[:top_holders_count], 1):
            # ä»explorerUrlä¸­æå–é’±åŒ…åœ°å€ï¼Œæˆ–ç›´æ¥ä½¿ç”¨holderWalletAddress
            explorer_url = holder.get("explorerUrl", "")
            if "solscan.io/account/" in explorer_url:
                wallet_address = explorer_url.split("solscan.io/account/")[-1]
            else:
                wallet_address = holder.get("holderWalletAddress", "") or holder.get("holderAddress", "")

            if not wallet_address:
                self.log_info(f"å¤§æˆ· #{i} æ— æ³•è·å–é’±åŒ…åœ°å€")
                continue

            self.log_info(f"åˆ†æå¤§æˆ· #{i}: {wallet_address[:8]}...{wallet_address[-6:]}")

            # è·å–é’±åŒ…èµ„äº§
            assets_data = self.get_wallet_assets(wallet_address)

            if assets_data:
                # æå–æ‰€æœ‰æœ‰ä»·å€¼çš„ä»£å¸
                top_tokens = self.extract_top_tokens(assets_data)

                # åªæœ‰å½“æˆåŠŸæå–åˆ°ä»£å¸æ—¶æ‰æ·»åŠ åˆ°åˆ†æç»“æœ
                if top_tokens:
                    holder_info = {
                        "rank": i,
                        "address": wallet_address,
                        "hold_amount": holder.get("holdAmount", "0"),
                        "hold_percentage": holder.get("holdAmountPercentage", "0"),
                        "top_tokens": top_tokens,
                    }

                    holder_analysis.append(holder_info)
                    self.log_info(f"å¤§æˆ· #{i} åˆ†æå®Œæˆï¼Œå‘ç° {len(top_tokens)} ä¸ªæœ‰ä»·å€¼ä»£å¸")
                else:
                    self.log_info(f"å¤§æˆ· #{i} æ²¡æœ‰å‘ç°æœ‰ä»·å€¼çš„ä»£å¸")
            else:
                self.log_info(f"å¤§æˆ· #{i} è·å–èµ„äº§å¤±è´¥")

            # æ·»åŠ å»¶è¿Ÿé¿å…é¢‘ç‡é™åˆ¶
            time.sleep(1)

        # 3. ç»Ÿè®¡æ‰€æœ‰å¤§æˆ·æŒæœ‰çš„ä»£å¸ï¼Œæ¯ä¸ªå¤§æˆ·æ¯ä¸ªä»£å¸åªè®¡ç®—ä¸€æ¬¡
        all_tokens = {}
        target_token_holders = set()  # è®°å½•æŒæœ‰ç›®æ ‡ä»£å¸çš„å¤§æˆ·åœ°å€

        for holder in holder_analysis:
            # å¯¹äºæ¯ä¸ªå¤§æˆ·ï¼Œè®°å½•ä»–æŒæœ‰çš„å”¯ä¸€ä»£å¸ï¼ˆé¿å…é‡å¤è®¡ç®—ï¼‰
            holder_unique_tokens = {}

            # å…ˆæ”¶é›†è¯¥å¤§æˆ·çš„æ‰€æœ‰å”¯ä¸€ä»£å¸
            for token in holder["top_tokens"]:
                symbol = token["symbol"]
                token_address_current = token["address"]

                # æ£€æŸ¥æ˜¯å¦æ˜¯ç›®æ ‡ä»£å¸
                if token_address_current == token_address:
                    target_token_holders.add(holder["address"])

                # ä½¿ç”¨addressä½œä¸ºé”®ï¼Œè¿™æ ·å¯ä»¥åŒºåˆ†ä¸åŒçš„ä»£å¸ï¼ˆå³ä½¿åå­—ç›¸åŒï¼‰
                if token_address_current not in holder_unique_tokens:
                    holder_unique_tokens[token_address_current] = {
                        "symbol": symbol,
                        "name": token["name"],
                        "chain": token["chain"],
                        "address": token_address_current,
                        "price_usd": token["price_usd"],
                        "total_balance": token["balance"],
                        "total_value_usd": token["value_usd"],
                        "is_target_token": token_address_current == token_address,
                    }
                else:
                    # å¦‚æœå·²å­˜åœ¨ï¼Œç´¯åŠ æ•°å€¼
                    holder_unique_tokens[token_address_current]["total_balance"] += token["balance"]
                    holder_unique_tokens[token_address_current]["total_value_usd"] += token[
                        "value_usd"
                    ]
                    # å¦‚æœæ˜¯ç›®æ ‡ä»£å¸ï¼Œæ ‡è®°å®ƒ
                    if token_address_current == token_address:
                        holder_unique_tokens[token_address_current]["is_target_token"] = True

            # ç°åœ¨ç»Ÿè®¡åˆ°å…¨å±€ä»£å¸è®°å½•ä¸­ï¼Œæ¯ä¸ªå¤§æˆ·æ¯ä¸ªä»£å¸åªè®¡ç®—ä¸€æ¬¡
            for token_addr, token_data in holder_unique_tokens.items():
                if token_addr not in all_tokens:
                    all_tokens[token_addr] = {
                        "symbol": token_data["symbol"],
                        "name": token_data["name"],
                        "chain": token_data["chain"],
                        "address": token_data["address"],
                        "price_usd": token_data["price_usd"],
                        "total_value": 0,
                        "holder_count": 0,
                        "holders_details": [],
                        "is_target_token": token_data["is_target_token"],
                    }
                else:
                    # å¦‚æœæ˜¯ç›®æ ‡ä»£å¸ï¼Œç¡®ä¿æ ‡è®°æ­£ç¡®
                    if token_data["is_target_token"]:
                        all_tokens[token_addr]["is_target_token"] = True

                # æ¯ä¸ªå¤§æˆ·æ¯ä¸ªä»£å¸åªè®¡ç®—ä¸€æ¬¡
                all_tokens[token_addr]["total_value"] += token_data["total_value_usd"]
                all_tokens[token_addr]["holder_count"] += 1

                # æ·»åŠ å¤§æˆ·æŒæœ‰è¯¦æƒ…
                holder_detail = {
                    "holder_rank": holder["rank"],
                    "holder_address": holder["address"],
                    "balance": token_data["total_balance"],
                    "value_usd": token_data["total_value_usd"],
                }
                all_tokens[token_addr]["holders_details"].append(holder_detail)

        # è¿‡æ»¤æ€»ä»·å€¼å¤§äº20Uçš„ä»£å¸ï¼Œç„¶åæŒ‰æ€»ä»·å€¼æ’åº
        filtered_tokens = [token for token in all_tokens.values() if token["total_value"] >= 20]
        sorted_tokens = sorted(filtered_tokens, key=lambda x: x["total_value"], reverse=True)

        analysis_result = {
            "token_address": token_address,
            "analysis_time": datetime.now().isoformat(),
            "filtering_stats": {
                "original_holders_count": len(holders),
                "excluded_holders_count": excluded_count,
                "filtered_holders_count": len(filtered_holders),
                "analyzed_holders_count": len(holder_analysis)
            },
            "total_holders_analyzed": len(holder_analysis),
            "target_token_actual_holders": len(target_token_holders),  # æ·»åŠ å®é™…æŒæœ‰ç›®æ ‡ä»£å¸çš„äººæ•°
            "original_holders_data": holders,  # ä¿å­˜åŸå§‹æŒæœ‰è€…æ•°æ®ç”¨äºæ’ååˆ†æ
            "token_statistics": {
                "total_unique_tokens": len(filtered_tokens),
                "total_portfolio_value": sum(token["total_value"] for token in sorted_tokens),
                "top_tokens_by_value": sorted_tokens,
            },
        }

        # ä¿å­˜è¯¦ç»†æ—¥å¿—åˆ°æ–‡ä»¶
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        log_file = self.data_manager.get_file_path("analysis", f"analysis_{token_address}_{timestamp}.json")
        with open(log_file, "w", encoding="utf-8") as f:
            json.dump(analysis_result, f, ensure_ascii=False, indent=2)

        self.log_info(f"åˆ†æå®Œæˆï¼Œç»“æœå·²ä¿å­˜åˆ°: {log_file}")
        self.log_info(f"è¿‡æ»¤ç»Ÿè®¡: åŸå§‹ {len(holders)} ä¸ªæŒæœ‰è€…ï¼Œæ’é™¤ {excluded_count} ä¸ªæµåŠ¨æ€§æ± /äº¤æ˜“æ‰€ï¼Œåˆ†æ {len(holder_analysis)} ä¸ªçœŸå®æŠ•èµ„è€…")
        self.log_info(
            f"å‘ç° {len(all_tokens)} ç§ä»£å¸ï¼Œè¿‡æ»¤å {len(filtered_tokens)} ç§ä»£å¸(â‰¥$20)ï¼Œæ€»ä»·å€¼ ${sum(token['total_value'] for token in sorted_tokens):,.2f}"
        )

        return analysis_result


def analyze_target_token_rankings(analysis_result: Dict, original_holders: List[Dict] = None) -> Dict:
    """
    åˆ†æç›®æ ‡ä»£å¸åœ¨å„ä¸ªåœ°å€å†…çš„ä»·å€¼æ’å
    
    Args:
        analysis_result: analyze_token_holders çš„ç»“æœ
        original_holders: åŸå§‹æŒæœ‰è€…æ•°æ®ï¼Œç”¨äºè·å–å‡†ç¡®çš„ç›®æ ‡ä»£å¸æŒä»“ä»·å€¼
        
    Returns:
        Dict: æ’ååˆ†æç»“æœï¼ŒåŒ…å«æ’ååˆ†å¸ƒå’Œç»Ÿè®¡
    """
    token_stats = analysis_result.get("token_statistics", {})
    all_tokens = token_stats.get("top_tokens_by_value", [])
    target_token_address = analysis_result.get("token_address", "")
    
    if not all_tokens or not target_token_address:
        return {"rankings": [], "statistics": {}}
    
    # æ‰¾åˆ°ç›®æ ‡ä»£å¸ä¿¡æ¯
    target_token = None
    for token in all_tokens:
        if token.get("address") == target_token_address:
            target_token = token
            break
    
    if not target_token:
        return {"rankings": [], "statistics": {}}
    
    # æ„å»ºåŸå§‹æŒæœ‰è€…çš„ç›®æ ‡ä»£å¸ä¿¡æ¯å­—å…¸
    original_target_holders = {}
    if original_holders:
        for holder in original_holders:
            wallet_address = holder.get("holderWalletAddress", "")
            if wallet_address:
                original_target_holders[wallet_address] = {
                    "holdVolume": float(holder.get("holdVolume", 0)),
                    "holdAmountPercentage": float(holder.get("holdAmountPercentage", 0)),
                    "holdAmount": holder.get("holdAmount", "0")
                }
    
    # æ„å»ºæ‰€æœ‰åˆ†æçš„å¤§æˆ·åœ°å€é›†åˆ
    all_analyzed_addresses = set()
    for token in all_tokens:
        for holder_info in token.get("holders_details", []):
            holder_address = holder_info.get("holder_address")
            if holder_address:
                all_analyzed_addresses.add(holder_address)
    
    print(f"æ€»å…±åˆ†æäº† {len(all_analyzed_addresses)} ä¸ªå¤§æˆ·åœ°å€")
    
    # æ„å»ºæ¯ä¸ªåœ°å€çš„ä»£å¸ä»·å€¼æ’å
    address_rankings = []
    
    # è·å–æŒæœ‰ç›®æ ‡ä»£å¸çš„åœ°å€
    target_holders_dict = {}
    for holder_detail in target_token.get("holders_details", []):
        holder_address = holder_detail.get("holder_address")
        if holder_address:
            target_holders_dict[holder_address] = holder_detail
    
    print(f"å…¶ä¸­ {len(target_holders_dict)} ä¸ªåœ°å€æŒæœ‰ç›®æ ‡ä»£å¸")
    
    # éå†æ‰€æœ‰åˆ†æçš„å¤§æˆ·åœ°å€
    for holder_address in all_analyzed_addresses:
        # æ”¶é›†è¯¥åœ°å€æŒæœ‰çš„æ‰€æœ‰ä»£å¸ä»·å€¼ï¼ˆå‰10å¤§æŒä»“ï¼‰
        holder_tokens = []
        
        for token in all_tokens:
            for holder_info in token.get("holders_details", []):
                if holder_info.get("holder_address") == holder_address:
                    holder_tokens.append({
                        "symbol": token["symbol"],
                        "address": token["address"],
                        "value_usd": holder_info.get("value_usd", 0),
                        "is_target": token["address"] == target_token_address
                    })
                    break
        
        # æŒ‰ä»·å€¼æ’åºï¼Œè·å–è¯¥åœ°å€çš„æŠ•èµ„ç»„åˆæ’å
        holder_tokens.sort(key=lambda x: x["value_usd"], reverse=True)
        
        # æ‰¾åˆ°ç›®æ ‡ä»£å¸çš„æ’å
        target_rank = None
        target_value = 0
        
        for i, token in enumerate(holder_tokens, 1):
            if token["is_target"]:
                target_rank = i
                target_value = token["value_usd"]
                break
        
        # ç¡®å®šè¯¥åœ°å€åœ¨åŸå§‹å¤§æˆ·æ’è¡Œæ¦œä¸­çš„æ’å
        holder_rank = 0
        if holder_address in target_holders_dict:
            holder_rank = target_holders_dict[holder_address].get("holder_rank", 0)
        else:
            # å¦‚æœä¸åœ¨ç›®æ ‡ä»£å¸æŒæœ‰è€…ä¸­ï¼Œå°è¯•ä»å…¶ä»–ä»£å¸çš„æŒæœ‰è€…ä¿¡æ¯ä¸­æ‰¾åˆ°æ’å
            for token in all_tokens:
                for holder_info in token.get("holders_details", []):
                    if holder_info.get("holder_address") == holder_address:
                        holder_rank = holder_info.get("holder_rank", 0)
                        break
                if holder_rank > 0:
                    break
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç›®æ ‡ä»£å¸ï¼Œè¯´æ˜æ’å>10ï¼Œä½†æ£€æŸ¥åŸå§‹æ•°æ®
        if target_rank is None:
            target_rank = 11  # è¡¨ç¤º>10å
            # ä»åŸå§‹æŒæœ‰è€…æ•°æ®ä¸­è·å–ç›®æ ‡ä»£å¸ä»·å€¼
            if holder_address in original_target_holders:
                target_value = original_target_holders[holder_address]["holdVolume"]
            else:
                target_value = 0   # è¯¥åœ°å€ç¡®å®ä¸æŒæœ‰ç›®æ ‡ä»£å¸
        
        # è®¡ç®—ç›®æ ‡ä»£å¸ä»·å€¼å æ¯”ï¼Œåˆ¤æ–­æ˜¯å¦ä¸ºé˜´è°‹é’±åŒ…
        portfolio_total_value = sum(token["value_usd"] for token in holder_tokens)
        
        # å¦‚æœç›®æ ‡ä»£å¸ä¸åœ¨å‰10åï¼Œéœ€è¦åŠ ä¸Šç›®æ ‡ä»£å¸ä»·å€¼åˆ°æ€»ä»·å€¼ä¸­
        if target_rank > 10 and target_value > 0:
            portfolio_total_value += target_value
        
        target_percentage = 0
        is_conspiracy_wallet = False
        
        if portfolio_total_value > 0 and target_value > 0:
            target_percentage = (target_value / portfolio_total_value) * 100
            is_conspiracy_wallet = target_percentage > 50  # é˜´è°‹é’±åŒ…ï¼šç›®æ ‡ä»£å¸å æ¯”>50%
        
        # è·å–ç›®æ ‡ä»£å¸çš„æŒæœ‰ç™¾åˆ†æ¯”ï¼ˆå æ€»ä¾›åº”é‡ï¼‰
        target_supply_percentage = 0
        if holder_address in original_target_holders:
            target_supply_percentage = original_target_holders[holder_address]["holdAmountPercentage"]
        
        address_rankings.append({
            "holder_address": holder_address,
            "holder_rank": holder_rank,
            "target_token_rank": target_rank,
            "target_token_value": target_value,
            "target_supply_percentage": target_supply_percentage,  # å æ€»ä¾›åº”é‡ç™¾åˆ†æ¯”
            "total_tokens": len(holder_tokens),
            "portfolio_value": portfolio_total_value,
            "target_percentage": target_percentage,
            "is_conspiracy_wallet": is_conspiracy_wallet
        })
    
    print(f"æœ€ç»ˆç»Ÿè®¡äº† {len(address_rankings)} ä¸ªåœ°å€çš„æ’å")
    
    # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
    if address_rankings:
        ranks = [addr["target_token_rank"] for addr in address_rankings]
        
        # æ’ååˆ†å¸ƒç»Ÿè®¡
        rank_distribution = {}
        for rank in ranks:
            if rank <= 10:
                rank_key = f"ç¬¬{rank}å"
            else:
                rank_key = ">10å"
            rank_distribution[rank_key] = rank_distribution.get(rank_key, 0) + 1
        
        # åŸºç¡€ç»Ÿè®¡ï¼ˆåªè®¡ç®—å®é™…æŒæœ‰çš„åœ°å€ï¼Œæ’é™¤>10åï¼‰
        actual_ranks = [r for r in ranks if r <= 10]
        if actual_ranks:
            avg_rank = sum(actual_ranks) / len(actual_ranks)
            median_rank = sorted(actual_ranks)[len(actual_ranks) // 2]
        else:
            avg_rank = 0
            median_rank = 0
        
        # é˜´è°‹é’±åŒ…ç»Ÿè®¡
        conspiracy_wallets = [addr for addr in address_rankings if addr["is_conspiracy_wallet"]]
        conspiracy_count = len(conspiracy_wallets)
        conspiracy_total_value = sum(wallet["target_token_value"] for wallet in conspiracy_wallets)
        
        # æ™ºèƒ½åˆ†æ
        analysis_text = _generate_ranking_analysis(address_rankings, avg_rank, rank_distribution)
        
        statistics = {
            "total_addresses": len(address_rankings),
            "actual_holders": len(actual_ranks),  # å®é™…æŒæœ‰ç›®æ ‡ä»£å¸çš„åœ°å€æ•°
            "conspiracy_wallets": conspiracy_count,  # é˜´è°‹é’±åŒ…æ•°é‡
            "conspiracy_total_value": conspiracy_total_value,  # é˜´è°‹é’±åŒ…æ€»ä»·å€¼
            "average_rank": avg_rank,
            "median_rank": median_rank,
            "rank_distribution": rank_distribution,
            "top3_count": len([r for r in ranks if r <= 3]),
            "top5_count": len([r for r in ranks if r <= 5]),
            "top10_count": len([r for r in ranks if r <= 10]),
            "over10_count": len([r for r in ranks if r > 10]),
            "analysis": analysis_text
        }
    else:
        statistics = {
            "total_addresses": 0,
            "actual_holders": 0,
            "conspiracy_wallets": 0,
            "conspiracy_total_value": 0,
            "average_rank": 0,
            "median_rank": 0,
            "rank_distribution": {},
            "analysis": "æœªæ‰¾åˆ°åˆ†ææ•°æ®"
        }
    
    return {
        "target_token": {
            "symbol": target_token["symbol"],
            "address": target_token_address
        },
        "rankings": address_rankings,
        "statistics": statistics
    }


def _generate_ranking_analysis(rankings: List[Dict], avg_rank: float, distribution: Dict) -> str:
    """ç”Ÿæˆç®€åŒ–çš„æŠ•èµ„å»ºè®®åˆ†æ - ä¸“æ³¨äºé˜´è°‹æŒä»“æ¯”ä¾‹å’Œå¤§æˆ·æŒä»“ä¿¡å¿ƒ"""
    # 1. è®¡ç®—åŸºç¡€æŒ‡æ ‡
    metrics = _calculate_analysis_metrics(rankings)
    
    analysis_parts = []
    
    # 2. é˜´è°‹é’±åŒ…é£é™©è¯„ä¼°
    conspiracy_analysis = _analyze_conspiracy_risk(metrics)
    analysis_parts.append(conspiracy_analysis)
    
    # 3. å¤§æˆ·æŒä»“ä¿¡å¿ƒè¯„ä¼°
    confidence_analysis = _analyze_holder_confidence(avg_rank, metrics)
    analysis_parts.append(confidence_analysis)
    
    # 4. å¤§æˆ·åˆ†å¸ƒä¿¡å¿ƒè¡¥å……
    distribution_analysis = _analyze_distribution_confidence(metrics)
    analysis_parts.append(distribution_analysis)
    
    # 5. ç»¼åˆæŠ•èµ„å»ºè®®
    investment_advice = _generate_investment_advice(metrics, avg_rank)
    analysis_parts.append(investment_advice)
    
    return " ".join(analysis_parts)


def _calculate_analysis_metrics(rankings: List[Dict]) -> Dict:
    """è®¡ç®—åˆ†ææ‰€éœ€çš„æ‰€æœ‰æŒ‡æ ‡"""
    total_addresses = len(rankings)
    
    # é˜´è°‹é’±åŒ…ç›¸å…³
    conspiracy_wallets = [r for r in rankings if r.get("is_conspiracy_wallet", False)]
    conspiracy_count = len(conspiracy_wallets)
    conspiracy_supply = sum(r.get("target_supply_percentage", 0) for r in conspiracy_wallets)
    
    # æ’ååˆ†å¸ƒç»Ÿè®¡
    top3_count = len([r for r in rankings if r["target_token_rank"] <= 3])
    top5_count = len([r for r in rankings if r["target_token_rank"] <= 5])
    top10_count = len([r for r in rankings if r["target_token_rank"] <= 10])
    
    # ç™¾åˆ†æ¯”è®¡ç®—
    top3_pct = (top3_count / total_addresses) * 100 if total_addresses > 0 else 0
    top5_pct = (top5_count / total_addresses) * 100 if total_addresses > 0 else 0
    top10_pct = (top10_count / total_addresses) * 100 if total_addresses > 0 else 0
    
    # æ€»æµé€šé‡
    total_supply = sum(r.get("target_supply_percentage", 0) for r in rankings)
    conspiracy_risk_ratio = conspiracy_supply / total_supply if total_supply > 0 else 0
    
    return {
        "total_addresses": total_addresses,
        "conspiracy_count": conspiracy_count,
        "conspiracy_supply": conspiracy_supply,
        "conspiracy_risk_ratio": conspiracy_risk_ratio,
        "top3_count": top3_count,
        "top5_count": top5_count,
        "top10_count": top10_count,
        "top3_pct": top3_pct,
        "top5_pct": top5_pct,
        "top10_pct": top10_pct,
        "total_supply": total_supply
    }


def _analyze_conspiracy_risk(metrics: Dict) -> str:
    """åˆ†æé˜´è°‹é’±åŒ…é£é™©"""
    conspiracy_count = metrics["conspiracy_count"]
    conspiracy_supply = metrics["conspiracy_supply"]
    conspiracy_risk_ratio = metrics["conspiracy_risk_ratio"]
    
    if conspiracy_count == 0:
        return "âœ… æ— é˜´è°‹é£é™©ï¼šæœªå‘ç°è¿‡åº¦é›†ä¸­æŒä»“é’±åŒ…"
    
    if conspiracy_risk_ratio >= 0.6:
        return f"ğŸ”´ é˜´è°‹é£é™©æé«˜ï¼š{conspiracy_count}ä¸ªé’±åŒ…è¿‡åº¦é›†ä¸­({conspiracy_supply:.1f}%)ï¼Œç ¸ç›˜é£é™©å¤§"
    elif conspiracy_risk_ratio >= 0.3:
        return f"ğŸŸ¡ é˜´è°‹é£é™©ä¸­ç­‰ï¼š{conspiracy_count}ä¸ªé’±åŒ…é›†ä¸­æŒä»“({conspiracy_supply:.1f}%)ï¼Œéœ€è°¨æ…"
    else:
        return f"ğŸŸ¢ é˜´è°‹é£é™©è¾ƒä½ï¼š{conspiracy_count}ä¸ªé›†ä¸­é’±åŒ…å æ¯”{conspiracy_supply:.1f}%ï¼Œå¯æ§"


def _analyze_holder_confidence(avg_rank: float, metrics: Dict) -> str:
    """åˆ†æå¤§æˆ·æŒä»“ä¿¡å¿ƒ"""
    if avg_rank <= 0:
        return "âš¡ å¤§æˆ·ä¿¡å¿ƒåå¼±ï¼šæ— æœ‰æ•ˆæŒä»“æ•°æ®"
    
    if avg_rank <= 3:
        return "ğŸ”¥ å¤§æˆ·ä¿¡å¿ƒæå¼ºï¼šå¹³å‡æ’åå‰3ï¼Œå±æ ¸å¿ƒé‡ä»“èµ„äº§"
    elif avg_rank <= 5:
        return "ğŸš€ å¤§æˆ·ä¿¡å¿ƒè¾ƒå¼ºï¼šå¹³å‡æ’åå‰5ï¼Œå±é‡è¦é…ç½®"
    elif avg_rank <= 8:
        return "ğŸ“ˆ å¤§æˆ·ä¿¡å¿ƒä¸€èˆ¬ï¼šå¹³å‡æ’åä¸­ç­‰ï¼Œé€‚åº¦é…ç½®"
    else:
        return "âš¡ å¤§æˆ·ä¿¡å¿ƒåå¼±ï¼šæ’ååä½ï¼Œå¤šä¸ºè¯•æ¢æ€§é…ç½®"


def _analyze_distribution_confidence(metrics: Dict) -> str:
    """åˆ†æå¤§æˆ·åˆ†å¸ƒä¿¡å¿ƒ"""
    top3_pct = metrics["top3_pct"]
    top5_pct = metrics["top5_pct"]
    top10_pct = metrics["top10_pct"]
    
    if top3_pct >= 50:
        return f"ğŸ’ª {top3_pct:.1f}%å¤§æˆ·å°†å…¶åˆ—ä¸ºå‰3é‡ä»“ï¼Œä¿¡å¿ƒåº¦æé«˜"
    elif top5_pct >= 50:
        return f"â­ {top5_pct:.1f}%å¤§æˆ·å°†å…¶åˆ—ä¸ºå‰5é…ç½®ï¼Œè®¤å¯åº¦è¾ƒé«˜"
    elif top10_pct >= 50:
        return f"ğŸ“Š {top10_pct:.1f}%å¤§æˆ·å°†å…¶åˆ—ä¸ºå‰10é…ç½®ï¼Œæœ‰åŸºç¡€å…±è¯†"
    else:
        return "ğŸ”„ å¤šæ•°å¤§æˆ·ä»…è¯•æ¢æ€§é…ç½®ï¼Œæ•´ä½“ä¿¡å¿ƒä¸è¶³"


def _generate_investment_advice(metrics: Dict, avg_rank: float) -> str:
    """ç”ŸæˆæŠ•èµ„å»ºè®®"""
    # è¯„ä¼°é˜´è°‹é£é™©ç­‰çº§
    conspiracy_risk = _evaluate_conspiracy_risk(metrics)
    
    # è¯„ä¼°å¤§æˆ·ä¿¡å¿ƒç­‰çº§
    holder_confidence = _evaluate_holder_confidence(avg_rank, metrics)
    
    # æŠ•èµ„å»ºè®®æ˜ å°„è¡¨
    advice_map = {
        ("æ— é£é™©", "æå¼º"): "âœ… æŠ•èµ„å»ºè®®ï¼šBUY - é˜´è°‹é£é™©ä½ï¼Œå¤§æˆ·ä¿¡å¿ƒå¼ºï¼Œé€‚åˆé‡ä»“",
        ("æ— é£é™©", "è¾ƒå¼º"): "âœ… æŠ•èµ„å»ºè®®ï¼šBUY - é˜´è°‹é£é™©ä½ï¼Œå¤§æˆ·ä¿¡å¿ƒå¼ºï¼Œé€‚åˆé‡ä»“",
        ("ä½é£é™©", "æå¼º"): "âœ… æŠ•èµ„å»ºè®®ï¼šBUY - é˜´è°‹é£é™©å¯æ§ï¼Œå¤§æˆ·çœ‹å¥½ï¼Œæ¨èé…ç½®",
        ("ä½é£é™©", "è¾ƒå¼º"): "âœ… æŠ•èµ„å»ºè®®ï¼šBUY - é˜´è°‹é£é™©å¯æ§ï¼Œå¤§æˆ·çœ‹å¥½ï¼Œæ¨èé…ç½®",
        ("æ— é£é™©", "ä¸€èˆ¬"): "ğŸ“Š æŠ•èµ„å»ºè®®ï¼šHODL - é£é™©å¯æ§ä½†ä¿¡å¿ƒä¸€èˆ¬ï¼Œé€‚åº¦é…ç½®",
        ("ä½é£é™©", "ä¸€èˆ¬"): "ğŸ“Š æŠ•èµ„å»ºè®®ï¼šHODL - é£é™©å¯æ§ä½†ä¿¡å¿ƒä¸€èˆ¬ï¼Œé€‚åº¦é…ç½®",
        ("ä¸­é£é™©", "æå¼º"): "âš ï¸ æŠ•èµ„å»ºè®®ï¼šå°ä»“ä½ - å¤§æˆ·çœ‹å¥½ä½†æœ‰é˜´è°‹é£é™©ï¼Œæ§åˆ¶ä»“ä½",
        ("ä¸­é£é™©", "è¾ƒå¼º"): "âš ï¸ æŠ•èµ„å»ºè®®ï¼šå°ä»“ä½ - å¤§æˆ·çœ‹å¥½ä½†æœ‰é˜´è°‹é£é™©ï¼Œæ§åˆ¶ä»“ä½",
        ("é«˜é£é™©", "*"): "ğŸ”´ æŠ•èµ„å»ºè®®ï¼šPASS - é˜´è°‹é£é™©è¿‡é«˜ï¼Œä¸å»ºè®®æŠ•èµ„"
    }
    
    # ä¼˜å…ˆæ£€æŸ¥é«˜é£é™©æƒ…å†µ
    if conspiracy_risk == "é«˜é£é™©":
        return advice_map[("é«˜é£é™©", "*")]
    
    # æŸ¥æ‰¾åŒ¹é…çš„å»ºè®®
    advice_key = (conspiracy_risk, holder_confidence)
    if advice_key in advice_map:
        return advice_map[advice_key]
    
    # é»˜è®¤å»ºè®®
    return "âš¡ æŠ•èµ„å»ºè®®ï¼šè§‚æœ› - å¤§æˆ·ä¿¡å¿ƒä¸è¶³ï¼Œå»ºè®®ç­‰å¾…æ›´å¥½æ—¶æœº"


def _evaluate_conspiracy_risk(metrics: Dict) -> str:
    """è¯„ä¼°é˜´è°‹é£é™©ç­‰çº§"""
    conspiracy_count = metrics["conspiracy_count"]
    conspiracy_risk_ratio = metrics["conspiracy_risk_ratio"]
    
    if conspiracy_count == 0:
        return "æ— é£é™©"
    elif conspiracy_risk_ratio < 0.3:
        return "ä½é£é™©"
    elif conspiracy_risk_ratio < 0.6:
        return "ä¸­é£é™©"
    else:
        return "é«˜é£é™©"


def _evaluate_holder_confidence(avg_rank: float, metrics: Dict) -> str:
    """è¯„ä¼°å¤§æˆ·ä¿¡å¿ƒç­‰çº§"""
    top3_pct = metrics["top3_pct"]
    top5_pct = metrics["top5_pct"]
    top10_pct = metrics["top10_pct"]
    
    if avg_rank <= 3 and top3_pct >= 20:
        return "æå¼º"
    elif avg_rank <= 5 and top5_pct >= 15:
        return "è¾ƒå¼º"
    elif avg_rank <= 8 and top10_pct >= 10:
        return "ä¸€èˆ¬"
    else:
        return "åå¼±"


def analyze_address_clusters(analysis_result: Dict) -> Dict:
    """
    åˆ†æåœ°å€é›†ç¾¤ï¼šæ‰¾å‡ºå…±åŒæŒæœ‰ç›¸åŒä»£å¸çš„åœ°å€ç¾¤ä½“

    Args:
        analysis_result: analyze_token_holders çš„ç»“æœ

    Returns:
        Dict: é›†ç¾¤åˆ†æç»“æœ
    """
    try:
        from ..core.config import get_config

        config = get_config()
        CLUSTER_MIN_COMMON_TOKENS = config.analysis.cluster_min_common_tokens
        CLUSTER_MIN_ADDRESSES = config.analysis.cluster_min_addresses
        CLUSTER_MAX_ADDRESSES = config.analysis.cluster_max_addresses
    except ImportError:
        CLUSTER_MIN_COMMON_TOKENS = 3
        CLUSTER_MIN_ADDRESSES = 2
        CLUSTER_MAX_ADDRESSES = 10

    # è·å–æ‰€æœ‰ä»£å¸çš„æŒæœ‰è€…ä¿¡æ¯
    token_stats = analysis_result.get("token_statistics", {})
    all_tokens = token_stats.get("top_tokens_by_value", [])

    if not all_tokens:
        return {"clusters": []}

    # 1. æ„å»ºåœ°å€-ä»£å¸æ˜ å°„
    address_tokens = {}  # {address: set(token_addresses)}
    token_holders = {}  # {token_address: set(addresses)}

    for token in all_tokens:
        token_address = token["address"]
        holders_details = token.get("holders_details", [])

        if not token_address or not holders_details:
            continue

        token_holders[token_address] = set()

        for holder_detail in holders_details:
            holder_addr = holder_detail.get("holder_address")
            if not holder_addr:
                continue

            # è®°å½•è¯¥åœ°å€æŒæœ‰çš„ä»£å¸
            if holder_addr not in address_tokens:
                address_tokens[holder_addr] = set()
            address_tokens[holder_addr].add(token_address)

            # è®°å½•è¯¥ä»£å¸çš„æŒæœ‰è€…
            token_holders[token_address].add(holder_addr)

    # 2. å¯»æ‰¾åœ°å€é›†ç¾¤
    clusters = []
    processed_addresses = set()

    # æŒ‰æŒæœ‰ä»£å¸æ•°é‡æ’åºåœ°å€ï¼Œä¼˜å…ˆå¤„ç†æŒæœ‰ä»£å¸å¤šçš„åœ°å€
    sorted_addresses = sorted(address_tokens.items(), key=lambda x: len(x[1]), reverse=True)

    for addr, tokens in sorted_addresses:
        if addr in processed_addresses:
            continue

        if len(tokens) < CLUSTER_MIN_COMMON_TOKENS:
            continue

        # å¯»æ‰¾ä¸å½“å‰åœ°å€æœ‰å…±åŒä»£å¸çš„å…¶ä»–åœ°å€
        cluster_addresses = {addr}

        # éå†å…¶ä»–åœ°å€ï¼Œæ‰¾åˆ°æœ‰å…±åŒä»£å¸çš„
        for other_addr, other_tokens in sorted_addresses:
            if other_addr == addr or other_addr in processed_addresses:
                continue

            # è®¡ç®—å…±åŒä»£å¸
            shared_tokens = tokens & other_tokens

            if len(shared_tokens) >= CLUSTER_MIN_COMMON_TOKENS:
                cluster_addresses.add(other_addr)

                # é™åˆ¶é›†ç¾¤å¤§å°
                if len(cluster_addresses) >= CLUSTER_MAX_ADDRESSES:
                    break

        # è®¡ç®—é›†ç¾¤ä¸­æ‰€æœ‰åœ°å€çœŸæ­£çš„å…±åŒä»£å¸
        if len(cluster_addresses) >= CLUSTER_MIN_ADDRESSES:
            # æ‰¾å‡ºæ‰€æœ‰é›†ç¾¤åœ°å€éƒ½æŒæœ‰çš„ä»£å¸
            common_tokens = None
            for cluster_addr in cluster_addresses:
                if common_tokens is None:
                    common_tokens = address_tokens[cluster_addr].copy()
                else:
                    common_tokens &= address_tokens[cluster_addr]

        # å¦‚æœæ‰¾åˆ°äº†è¶³å¤Ÿçš„åœ°å€å½¢æˆé›†ç¾¤ä¸”æœ‰è¶³å¤Ÿçš„å…±åŒä»£å¸
        if (
            len(cluster_addresses) >= CLUSTER_MIN_ADDRESSES
            and len(common_tokens) >= CLUSTER_MIN_COMMON_TOKENS
        ):

            # æ”¶é›†å…±åŒä»£å¸çš„è¯¦ç»†ä¿¡æ¯
            cluster_tokens_info = []
            total_cluster_value = 0

            for token_addr in common_tokens:
                # æ‰¾åˆ°å¯¹åº”çš„ä»£å¸ä¿¡æ¯
                token_info = None
                for token in all_tokens:
                    if token["address"] == token_addr:
                        token_info = token
                        break

                if token_info:
                    # è®¡ç®—é›†ç¾¤åœ¨è¯¥ä»£å¸ä¸­çš„æ€»ä»·å€¼
                    cluster_value_in_token = 0
                    cluster_holders_in_token = []

                    for holder_detail in token_info.get("holders_details", []):
                        if holder_detail.get("holder_address") in cluster_addresses:
                            cluster_value_in_token += holder_detail.get("value_usd", 0)
                            cluster_holders_in_token.append(
                                {
                                    "address": holder_detail.get("holder_address"),
                                    "value_usd": holder_detail.get("value_usd", 0),
                                    "rank": holder_detail.get("holder_rank", 0),
                                }
                            )

                    cluster_tokens_info.append(
                        {
                            "symbol": token_info["symbol"],
                            "name": token_info["name"],
                            "address": token_addr,
                            "cluster_value": cluster_value_in_token,
                            "cluster_holders": cluster_holders_in_token,
                            "total_token_value": token_info["total_value"],
                            "cluster_percentage": (
                                (cluster_value_in_token / token_info["total_value"]) * 100
                                if token_info["total_value"] > 0
                                else 0
                            ),
                        }
                    )

                    total_cluster_value += cluster_value_in_token

            # æŒ‰é›†ç¾¤ä¸­æŒæœ‰è¯¥ä»£å¸çš„åœ°å€æ•°é‡æ’åº
            cluster_tokens_info.sort(key=lambda x: len(x["cluster_holders"]), reverse=True)

            cluster_info = {
                "cluster_id": len(clusters) + 1,
                "addresses": list(cluster_addresses),
                "address_count": len(cluster_addresses),
                "common_tokens": cluster_tokens_info,
                "common_tokens_count": len(common_tokens),
                "total_value": total_cluster_value,
                "avg_value_per_address": (
                    total_cluster_value / len(cluster_addresses)
                    if len(cluster_addresses) > 0
                    else 0
                ),
            }

            clusters.append(cluster_info)
            processed_addresses.update(cluster_addresses)

    # æŒ‰ä»£å¸æ•°é‡å’Œåœ°å€æ•°é‡ç»¼åˆæ’åºé›†ç¾¤
    # è®¡ç®—ç»¼åˆè¯„åˆ†ï¼šä»£å¸æ•°é‡ * åœ°å€æ•°é‡ (ä»£å¸æ•°é‡æƒé‡æ›´é«˜)
    clusters.sort(key=lambda x: x["common_tokens_count"] * x["address_count"], reverse=True)

    cluster_result = {
        "clusters": clusters,
        "analysis_summary": {
            "total_clusters": len(clusters),
            "total_addresses_in_clusters": sum(c["address_count"] for c in clusters),
            "cluster_config": {
                "min_common_tokens": CLUSTER_MIN_COMMON_TOKENS,
                "min_addresses": CLUSTER_MIN_ADDRESSES,
                "max_addresses": CLUSTER_MAX_ADDRESSES,
            },
        },
    }

    return cluster_result


def format_tokens_table(
    token_stats: Dict, max_tokens: int = None, sort_by: str = "value", cache_key: str = None
) -> tuple:
    """
    æ ¼å¼åŒ–ä»£å¸ç»Ÿè®¡è¡¨æ ¼ï¼Œä¸“é—¨ä¸ºTelegramæ¶ˆæ¯ä¼˜åŒ–

    Args:
        token_stats: ä»£å¸ç»Ÿè®¡æ•°æ®
        max_tokens: æ˜¾ç¤ºçš„æœ€å¤§ä»£å¸æ•°é‡ (å¦‚æœä¸ºNoneï¼Œä»é…ç½®æ–‡ä»¶è¯»å–)
        sort_by: æ’åºæ–¹å¼ ('value' æŒ‰æ€»ä»·å€¼, 'count' æŒ‰æŒæœ‰äººæ•°)
        cache_key: ç¼“å­˜é”®ï¼Œç”¨äºç”Ÿæˆè¯¦æƒ…æŒ‰é’®

    Returns:
        tuple: (æ¶ˆæ¯æ–‡æœ¬, æŒ‰é’®markupå¯¹è±¡)
    """
    # å¦‚æœæ²¡æœ‰æä¾›å‚æ•°ï¼Œä»é…ç½®æ–‡ä»¶è·å–
    if max_tokens is None:
        try:
            from ..core.config import get_config

            config = get_config()
            max_tokens = config.analysis.ranking_size
        except ImportError:
            max_tokens = 30  # å›é€€åˆ°é»˜è®¤å€¼

    # è·å–è¯¦æƒ…æŒ‰é’®æ•°é‡é…ç½®
    detail_buttons_count = max_tokens  # é»˜è®¤ä¸æ’è¡Œæ¦œå¤§å°ç›¸åŒ
    try:
        from ..core.config import get_config

        config = get_config()
        detail_buttons_count = config.analysis.detail_buttons_count
    except ImportError:
        pass
    if not token_stats or not token_stats.get("top_tokens_by_value"):
        return "âŒ æœªæ‰¾åˆ°ä»£å¸æ•°æ®", None

    # æ ¹æ®æ’åºæ–¹å¼é‡æ–°æ’åº
    all_tokens = token_stats["top_tokens_by_value"]
    if sort_by == "count":
        sorted_tokens = sorted(all_tokens, key=lambda x: x["holder_count"], reverse=True)
        sort_desc = "æŒ‰æŒæœ‰äººæ•°æ’åº"
        sort_icon = "ğŸ‘¥"
    else:
        sorted_tokens = sorted(all_tokens, key=lambda x: x["total_value"], reverse=True)
        sort_desc = "æŒ‰æ€»ä»·å€¼æ’åº"
        sort_icon = "ğŸ’°"

    sorted_tokens = sorted_tokens[:max_tokens]
    total_portfolio_value = token_stats.get("total_portfolio_value", 0)
    total_unique_tokens = token_stats.get("total_unique_tokens", 0)

    # æ„å»ºè¡¨æ ¼
    msg = f"ğŸ”¥ <b>å¤§æˆ·çƒ­é—¨ä»£å¸æ’è¡Œæ¦œ</b> ({sort_icon} {sort_desc})\n"
    msg += f"ğŸ’° æ€»èµ„äº§: <b>${total_portfolio_value:,.0f}</b>\n"
    msg += f"ğŸ”¢ ä»£å¸ç§ç±»: <b>{total_unique_tokens}</b>\n"
    msg += "â”€" * 35 + "\n"

    # åˆ›å»ºæŒ‰é’®å¸ƒå±€
    markup = None
    detail_buttons = []

    # ä¸ºå‰10ä¸ªä»£å¸åˆ›å»ºè¯¦æƒ…æŒ‰é’®
    if cache_key:
        try:
            # å°è¯•å¯¼å…¥telebot
            from telebot import types

            markup = types.InlineKeyboardMarkup()
        except ImportError:
            # å¦‚æœtelebotä¸å¯ç”¨ï¼Œè¿”å›None
            markup = None

    for i, token in enumerate(sorted_tokens, 1):
        symbol = token["symbol"][:8]  # é™åˆ¶é•¿åº¦
        value = token["total_value"]
        count = token["holder_count"]
        token_address = token.get("address", "")

        # æ ¼å¼åŒ–ä»·å€¼
        if value >= 1_000_000:
            value_str = f"${value/1_000_000:.1f}M"
        elif value >= 1_000:
            value_str = f"${value/1_000:.1f}K"
        else:
            value_str = f"${value:.0f}"

        # ä¸ºä»£å¸åç§°æ·»åŠ è¶…é“¾æ¥
        if token_address:
            gmgn_token_link = f"https://gmgn.ai/sol/token/{token_address}"
            symbol_with_link = f"<a href='{gmgn_token_link}'>{symbol}</a>"
        else:
            symbol_with_link = symbol

        if sort_by == "count":
            # æŒ‰æŒæœ‰äººæ•°æ’åºæ—¶ï¼Œçªå‡ºæ˜¾ç¤ºäººæ•°
            msg += f"<b>{i:2d}.</b> {symbol_with_link} <b>({count}äºº)</b> {value_str}\n"
        else:
            # æŒ‰ä»·å€¼æ’åºæ—¶ï¼Œçªå‡ºæ˜¾ç¤ºä»·å€¼
            msg += f"<b>{i:2d}.</b> {symbol_with_link} <b>{value_str}</b> ({count}äºº)\n"

        # ä¸ºä»£å¸æ·»åŠ è¯¦æƒ…æŒ‰é’®
        if i <= detail_buttons_count and cache_key and markup:
            button_text = f"{i}. {symbol}"
            # åœ¨å›è°ƒæ•°æ®ä¸­åŒ…å«æ’åºä¿¡æ¯
            callback_data = f"token_detail_{cache_key}_{i-1}_{sort_by}"  # æ·»åŠ æ’åºä¿¡æ¯
            try:
                from telebot import types

                detail_buttons.append(
                    types.InlineKeyboardButton(button_text, callback_data=callback_data)
                )
            except ImportError:
                pass

    # æ·»åŠ ä»£å¸è¯¦æƒ…æŒ‰é’®ï¼ˆæ¯è¡Œ3ä¸ªï¼‰
    if detail_buttons and cache_key:
        msg += f"\nğŸ’¡ <i>ç‚¹å‡»ä¸‹æ–¹æŒ‰é’®æŸ¥çœ‹å‰{min(detail_buttons_count, len(sorted_tokens))}ä¸ªä»£å¸çš„å¤§æˆ·è¯¦æƒ…</i>\n"

        # åˆ†è¡Œæ·»åŠ æŒ‰é’®ï¼Œæ¯è¡Œ3ä¸ª
        for i in range(0, len(detail_buttons), 3):
            row_buttons = detail_buttons[i : i + 3]
            markup.add(*row_buttons)

    return msg, markup


def format_token_holders_detail(token_info: Dict, token_stats: Dict) -> str:
    """
    æ ¼å¼åŒ–å•ä¸ªä»£å¸çš„å¤§æˆ·æŒæœ‰è¯¦æƒ…

    Args:
        token_info: ä»£å¸ä¿¡æ¯
        token_stats: å®Œæ•´çš„ä»£å¸ç»Ÿè®¡æ•°æ®

    Returns:
        str: æ ¼å¼åŒ–çš„å¤§æˆ·è¯¦æƒ…æ¶ˆæ¯
    """
    symbol = token_info["symbol"]
    name = token_info["name"]
    total_value = token_info["total_value"]
    holder_count = token_info["holder_count"]

    # æ ¼å¼åŒ–æ€»ä»·å€¼
    if total_value >= 1_000_000:
        value_str = f"${total_value/1_000_000:.2f}M"
    elif total_value >= 1_000:
        value_str = f"${total_value/1_000:.2f}K"
    else:
        value_str = f"${total_value:.2f}"

    msg = f"ğŸª™ <b>{symbol}</b> ({name}) å¤§æˆ·æŒæœ‰è¯¦æƒ…\n"
    msg += f"ğŸ’° æ€»æŒæœ‰ä»·å€¼: <b>{value_str}</b>\n"
    msg += f"ğŸ‘¥ æŒæœ‰å¤§æˆ·æ•°: <b>{holder_count} äºº</b>\n"
    msg += "â”€" * 40 + "\n"

    # è·å–æŒæœ‰è¯¥ä»£å¸çš„å¤§æˆ·è¯¦æƒ…
    holders_details = token_info.get("holders_details", [])

    # æ·»åŠ è°ƒè¯•ä¿¡æ¯
    print(f"è°ƒè¯•: {symbol} çš„ holders_details é•¿åº¦: {len(holders_details)}")

    if holders_details:
        # æŒ‰æŒæœ‰ä»·å€¼æ’åº
        sorted_holders = sorted(holders_details, key=lambda x: x.get("value_usd", 0), reverse=True)

        msg += "ğŸ“Š <b>å¤§æˆ·æŒæœ‰æ’è¡Œ</b>:\n\n"

        for i, holder in enumerate(sorted_holders, 1):
            holder_rank = holder.get("holder_rank", 0)
            holder_addr = holder.get("holder_address", "")
            balance = holder.get("balance", 0)
            value_usd = holder.get("value_usd", 0)

            # éªŒè¯æ•°æ®æœ‰æ•ˆæ€§
            if not holder_addr or value_usd <= 0:
                print(f"è­¦å‘Š: å¤§æˆ·#{holder_rank} æ•°æ®æ— æ•ˆ: addr={holder_addr}, value={value_usd}")
                continue

            # æ ¼å¼åŒ–åœ°å€æ˜¾ç¤ºå’Œè¶…é“¾æ¥
            addr_display = (
                f"{holder_addr[:6]}...{holder_addr[-4:]}" if len(holder_addr) >= 10 else holder_addr
            )
            gmgn_link = f"https://gmgn.ai/sol/address/{holder_addr}"
            addr_with_link = f"<a href='{gmgn_link}'>{addr_display} ğŸ”—</a>"

            # æ ¼å¼åŒ–æŒæœ‰ä»·å€¼
            if value_usd >= 1_000_000:
                holder_value_str = f"${value_usd/1_000_000:.2f}M"
            elif value_usd >= 1_000:
                holder_value_str = f"${value_usd/1_000:.2f}K"
            else:
                holder_value_str = f"${value_usd:.2f}"

            # æ ¼å¼åŒ–ä½™é¢
            if balance >= 1_000_000:
                balance_str = f"{balance/1_000_000:.2f}M"
            elif balance >= 1_000:
                balance_str = f"{balance/1_000:.2f}K"
            else:
                balance_str = f"{balance:,.2f}"

            msg += f"<b>{i:2d}.</b> å¤§æˆ·#{holder_rank} {addr_with_link}\n"
            msg += f"    ğŸ’° ä»·å€¼: <b>{holder_value_str}</b> | æ•°é‡: {balance_str}\n\n"

            # é™åˆ¶æ˜¾ç¤ºå‰15ä¸ªå¤§æˆ·ï¼Œé¿å…æ¶ˆæ¯è¿‡é•¿
            if i >= 15:
                remaining = len(sorted_holders) - 15
                if remaining > 0:
                    msg += f"... è¿˜æœ‰ {remaining} ä¸ªå¤§æˆ·æŒæœ‰è¯¥ä»£å¸\n"
                break
    else:
        msg += "âŒ æš‚æ— å¤§æˆ·è¯¦æƒ…æ•°æ®\n"
        msg += f"ğŸ’¡ <i>è¿™å¯èƒ½æ˜¯å› ä¸º:</i>\n"
        msg += f"â€¢ æ•°æ®æ”¶é›†è¿‡ç¨‹ä¸­å‡ºç°äº†é”™è¯¯\n"
        msg += f"â€¢ å¤§æˆ·èµ„äº§è·å–å¤±è´¥\n"
        msg += f"â€¢ ç½‘ç»œè¿æ¥é—®é¢˜\n"
        print(f"é”™è¯¯: {symbol} æ²¡æœ‰ holders_details æ•°æ®")

    return msg


def format_cluster_analysis(cluster_result: Dict, max_clusters: int = 5, page: int = 1, clusters_per_page: int = 3) -> str:
    """
    æ ¼å¼åŒ–é›†ç¾¤åˆ†æç»“æœä¸ºTelegramæ¶ˆæ¯

    Args:
        cluster_result: é›†ç¾¤åˆ†æç»“æœ
        max_clusters: æœ€å¤šæ˜¾ç¤ºçš„é›†ç¾¤æ•°é‡ï¼ˆå·²åºŸå¼ƒï¼Œä¸ºäº†å…¼å®¹æ€§ä¿ç•™ï¼‰
        page: å½“å‰é¡µç ï¼ˆä»1å¼€å§‹ï¼‰
        clusters_per_page: æ¯é¡µæ˜¾ç¤ºçš„é›†ç¾¤æ•°é‡

    Returns:
        str: æ ¼å¼åŒ–çš„æ¶ˆæ¯æ–‡æœ¬
    """
    clusters = cluster_result.get("clusters", [])
    summary = cluster_result.get("analysis_summary", {})

    if not clusters:
        return "âŒ æœªå‘ç°ç¬¦åˆæ¡ä»¶çš„åœ°å€é›†ç¾¤"

    total_clusters = summary.get("total_clusters", 0)
    total_pages = (len(clusters) + clusters_per_page - 1) // clusters_per_page  # å‘ä¸Šå–æ•´
    
    # ç¡®ä¿é¡µç åœ¨æœ‰æ•ˆèŒƒå›´å†…
    page = max(1, min(page, total_pages))
    
    # è®¡ç®—å½“å‰é¡µæ˜¾ç¤ºçš„é›†ç¾¤èŒƒå›´
    start_idx = (page - 1) * clusters_per_page
    end_idx = min(start_idx + clusters_per_page, len(clusters))
    
    msg = f"ğŸ¯ <b>åœ°å€é›†ç¾¤åˆ†æ</b> (ç¬¬{page}/{total_pages}é¡µ, å…±{total_clusters}ä¸ª)\n"
    msg += "â”€" * 35 + "\n\n"

    # æ˜¾ç¤ºå½“å‰é¡µçš„é›†ç¾¤
    displayed_clusters = clusters[start_idx:end_idx]

    for cluster in displayed_clusters:
        cluster_id = cluster["cluster_id"]
        addresses = cluster["addresses"]
        address_count = cluster["address_count"]
        total_value = cluster["total_value"]
        common_tokens = cluster["common_tokens"]
        common_tokens_count = cluster["common_tokens_count"]
        avg_value = cluster["avg_value_per_address"]

        # æ ¼å¼åŒ–æ€»ä»·å€¼
        if total_value >= 1_000_000:
            value_str = f"${total_value/1_000_000:.2f}M"
        elif total_value >= 1_000:
            value_str = f"${total_value/1_000:.2f}K"
        else:
            value_str = f"${total_value:.0f}"

        msg += f"ğŸ† <b>é›†ç¾¤ #{cluster_id}</b>\n"
        msg += f"ğŸ’° æ€»ä»·å€¼: <b>{value_str}</b> | å¹³å‡: ${avg_value:,.0f}/åœ°å€\n"
        msg += f"ğŸ‘¥ åœ°å€æ•°é‡: <b>{address_count}</b> | å…±åŒä»£å¸: <b>{common_tokens_count}</b>\n\n"

        # æ˜¾ç¤ºå…±åŒæŒæœ‰çš„ä»£å¸
        msg += "ğŸª™ <b>å…±åŒæŒæœ‰ä»£å¸</b>:\n"
        for i, token in enumerate(common_tokens[:5], 1):  # æœ€å¤šæ˜¾ç¤º5ä¸ªä»£å¸
            symbol = token["symbol"]
            token_address = token["address"]
            cluster_value = token["cluster_value"]
            cluster_percentage = token["cluster_percentage"]

            # æ ¼å¼åŒ–ä»£å¸ä»·å€¼
            if cluster_value >= 1_000_000:
                token_value_str = f"${cluster_value/1_000_000:.2f}M"
            elif cluster_value >= 1_000:
                token_value_str = f"${cluster_value/1_000:.2f}K"
            else:
                token_value_str = f"${cluster_value:.0f}"

            # æ·»åŠ ä»£å¸é“¾æ¥
            gmgn_link = f"https://gmgn.ai/sol/token/{token_address}"
            symbol_with_link = f"<a href='{gmgn_link}'>{symbol}</a>"

            msg += (
                f"  <b>{i}.</b> {symbol_with_link} {token_value_str} ({cluster_percentage:.1f}%)\n"
            )

        if len(common_tokens) > 5:
            msg += f"  ... è¿˜æœ‰ {len(common_tokens) - 5} ä¸ªä»£å¸\n"

        # æ˜¾ç¤ºæ‰€æœ‰åœ°å€ (å¸¦GMGNé“¾æ¥)
        msg += f"\nğŸ“ <b>é›†ç¾¤åœ°å€</b> ({address_count}ä¸ª):\n"
        for i, addr in enumerate(addresses, 1):
            addr_short = f"{addr[:6]}...{addr[-6:]}"
            gmgn_addr_link = f"https://gmgn.ai/sol/address/{addr}"
            msg += f"  {i}. <a href='{gmgn_addr_link}'>{addr_short}</a>\n"

        msg += "\n" + "â”€" * 30 + "\n\n"

    msg += f"\nğŸ¯ <b>é›†ç¾¤è¯´æ˜</b>\n"
    msg += f"â€¢ æŒ‰ ä»£å¸æ•°é‡Ã—åœ°å€æ•°é‡ ç»¼åˆè¯„åˆ†æ’åº\n"
    msg += f"â€¢ ç™¾åˆ†æ¯”ï¼šé›†ç¾¤åœ¨è¯¥ä»£å¸ä¸­çš„æŒä»“å å¤§æˆ·æ€»æŒä»“çš„æ¯”ä¾‹\n"

    return msg, page, total_pages


def format_target_token_rankings(ranking_result: Dict) -> str:
    """
    æ ¼å¼åŒ–ç›®æ ‡ä»£å¸æ’ååˆ†æç»“æœä¸ºTelegramæ¶ˆæ¯
    
    Args:
        ranking_result: æ’ååˆ†æç»“æœ
        
    Returns:
        str: æ ¼å¼åŒ–çš„æ¶ˆæ¯æ–‡æœ¬
    """
    target_token = ranking_result.get("target_token", {})
    rankings = ranking_result.get("rankings", [])
    statistics = ranking_result.get("statistics", {})
    
    if not rankings:
        return "âŒ æœªæ‰¾åˆ°æŒæœ‰ç›®æ ‡ä»£å¸çš„åœ°å€æ•°æ®"
    
    symbol = target_token.get("symbol", "Unknown")
    total_addresses = statistics.get("total_addresses", 0)
    actual_holders = statistics.get("actual_holders", 0)
    conspiracy_count = statistics.get("conspiracy_wallets", 0)
    conspiracy_total_value = statistics.get("conspiracy_total_value", 0)
    avg_rank = statistics.get("average_rank", 0)
    median_rank = statistics.get("median_rank", 0)
    distribution = statistics.get("rank_distribution", {})
    analysis = statistics.get("analysis", "")
    
    # è®¡ç®—é˜´è°‹é’±åŒ…æµé€šé‡å æ¯”ï¼ˆéœ€è¦åœ¨å‰é¢è®¡ç®—ï¼Œå› ä¸ºåé¢ä¼šç”¨åˆ°ï¼‰
    conspiracy_supply_percentage = sum(r.get("target_supply_percentage", 0) for r in rankings if r.get("is_conspiracy_wallet", False))
    
    msg = f"ğŸ“Š <b>{symbol} ä»·å€¼æ’ååˆ†æ</b>\n"
    msg += f"ğŸ¯ åˆ†æåœ°å€: <b>{total_addresses}</b> ä¸ªå¤§æˆ·\n"
    msg += f"ğŸ’ å®é™…æŒæœ‰: <b>{actual_holders}</b> ä¸ª ({(actual_holders/total_addresses)*100:.1f}%)\n"
    
    # é˜´è°‹é’±åŒ…ä¿¡æ¯
    if conspiracy_count > 0:
        conspiracy_percentage = (conspiracy_count / total_addresses) * 100
        if conspiracy_total_value >= 1_000_000:
            conspiracy_value_str = f"${conspiracy_total_value/1_000_000:.2f}M"
        elif conspiracy_total_value >= 1_000:
            conspiracy_value_str = f"${conspiracy_total_value/1_000:.2f}K"
        else:
            conspiracy_value_str = f"${conspiracy_total_value:.0f}"
        msg += f"ğŸ”´ é˜´è°‹é’±åŒ…: <b>{conspiracy_count}</b> ä¸ª ({conspiracy_supply_percentage:.1f}%) | æ€»å€¼: {conspiracy_value_str}\n"
    
    msg += "â”€" * 35 + "\n\n"
    
    # ç»Ÿè®¡ä¿¡æ¯
    if avg_rank > 0:
        msg += f"ğŸ“ˆ <b>æ’åç»Ÿè®¡</b> (ä»…ç»Ÿè®¡æŒæœ‰è€…)\n"
        msg += f"â€¢ å¹³å‡æ’å: <b>ç¬¬{avg_rank:.1f}å</b>\n"
        msg += f"â€¢ ä¸­ä½æ•°æ’å: <b>ç¬¬{median_rank}å</b>\n\n"
    else:
        msg += f"ğŸ“ˆ <b>æ’åç»Ÿè®¡</b>\n"
        msg += f"â€¢ æ‰€æœ‰åˆ†æåœ°å€å‡æœªæŒæœ‰ç›®æ ‡ä»£å¸\n\n"
    
    # è®¡ç®—æ¯ä¸ªæ’åçš„æ€»ä»·å€¼å’Œæ€»ä¾›åº”é‡å æ¯”
    rank_values = {}  # {rank: total_value}
    rank_supply_percentages = {}  # {rank: total_supply_percentage}
    
    for ranking in rankings:
        rank = ranking["target_token_rank"]
        value = ranking["target_token_value"]
        supply_percentage = ranking.get("target_supply_percentage", 0)
        
        if rank <= 10:
            rank_key = f"ç¬¬{rank}å"
        else:
            rank_key = ">10å"
        
        rank_values[rank_key] = rank_values.get(rank_key, 0) + value
        rank_supply_percentages[rank_key] = rank_supply_percentages.get(rank_key, 0) + supply_percentage
    
    # æ’ååˆ†å¸ƒï¼ˆæ˜¾ç¤ºå æµé€šé‡æ¯”ä¾‹ï¼‰
    msg += f"ğŸ“Š <b>æ’ååˆ†å¸ƒ</b> (å æµé€šé‡æ¯”ä¾‹)\n"
    
    # å®šä¹‰æ’ååŒºé—´å’Œå¯¹åº”emoji
    rank_ranges = [
        ("ç¬¬1å", "ğŸ¥‡"),
        ("ç¬¬2å", "ğŸ¥ˆ"), 
        ("ç¬¬3å", "ğŸ¥‰"),
        ("ç¬¬4å", "ğŸ…"),
        ("ç¬¬5å", "ğŸ…"),
        ("ç¬¬6å", "â­"),
        ("ç¬¬7å", "â­"),
        ("ç¬¬8å", "â­"),
        ("ç¬¬9å", "â­"),
        ("ç¬¬10å", "â­"),
    ]
    
    # ç»Ÿè®¡>10åçš„æƒ…å†µ
    over_10_count = len([r for r in rankings if r["target_token_rank"] > 10])
    if over_10_count > 0:
        distribution[">10å"] = over_10_count
        rank_values[">10å"] = sum(r["target_token_value"] for r in rankings if r["target_token_rank"] > 10)
        rank_supply_percentages[">10å"] = sum(r.get("target_supply_percentage", 0) for r in rankings if r["target_token_rank"] > 10)
    
    for rank_key, emoji in rank_ranges:
        count = distribution.get(rank_key, 0)
        if count > 0:
            supply_percentage = rank_supply_percentages.get(rank_key, 0)
            value = rank_values.get(rank_key, 0)
            if value >= 1_000_000:
                value_str = f"${value/1_000_000:.2f}M"
            elif value >= 1_000:
                value_str = f"${value/1_000:.2f}K"
            else:
                value_str = f"${value:.0f}"
            msg += f"{emoji} {rank_key}: <b>{count}</b> äºº ({value_str}) {supply_percentage:.2f}%\n"
    
    # æ·»åŠ >10åç»Ÿè®¡
    if over_10_count > 0:
        supply_percentage = rank_supply_percentages.get(">10å", 0)
        value = rank_values.get(">10å", 0)
        if value >= 1_000_000:
            value_str = f"${value/1_000_000:.2f}M"
        elif value >= 1_000:
            value_str = f"${value/1_000:.2f}K"
        else:
            value_str = f"${value:.0f}"
        # è®¡ç®—>10ååœ°å€çš„å¹³å‡æŒä»“ä»·å€¼
        avg_value = value / over_10_count if over_10_count > 0 else 0
        if avg_value >= 1000:
            avg_value_str = f"${avg_value/1000:.1f}K"
        else:
            avg_value_str = f"${avg_value:.0f}"
        msg += f"ğŸ“‰ >10å: <b>{over_10_count}</b> äºº ({value_str}, å‡å€¼: {avg_value_str}) {supply_percentage:.2f}%\n"
    
    # Topæ’åç»Ÿè®¡ - è®¡ç®—æµé€šé‡å æ¯”
    top3_count = statistics.get("top3_count", 0)
    top5_count = statistics.get("top5_count", 0) 
    top10_count = statistics.get("top10_count", 0)
    
    # è®¡ç®—å„å±‚çº§çš„æµé€šé‡å æ¯”
    top3_supply_percentage = sum(r.get("target_supply_percentage", 0) for r in rankings if r["target_token_rank"] <= 3)
    top5_supply_percentage = sum(r.get("target_supply_percentage", 0) for r in rankings if r["target_token_rank"] <= 5)
    top10_supply_percentage = sum(r.get("target_supply_percentage", 0) for r in rankings if r["target_token_rank"] <= 10)
    
    msg += f"\nğŸ¯ <b>é‡ç‚¹ç»Ÿè®¡</b>\n"
    msg += f"ğŸ”¥ å‰3å: <b>{top3_count}</b> äºº ({top3_supply_percentage:.2f}%)\n"
    msg += f"â­ å‰5å: <b>{top5_count}</b> äºº ({top5_supply_percentage:.2f}%)\n"
    msg += f"ğŸ“ˆ å‰10å: <b>{top10_count}</b> äºº ({top10_supply_percentage:.2f}%)\n"
    
    # é˜´è°‹é’±åŒ…ç»Ÿè®¡
    if conspiracy_count > 0:
        msg += f"ğŸ”´ é˜´è°‹é’±åŒ…: <b>{conspiracy_count}</b> äºº ({conspiracy_supply_percentage:.2f}%) | æŒä»“å æ¯”>50%\n"
    
    msg += "\n"
    
    # æ™ºèƒ½åˆ†æ
    msg += f"ğŸ§  <b>æ™ºèƒ½åˆ†æ</b>\n"
    msg += f"{analysis}\n\n"
    
    msg += f"â­ <i>ç‚¹å‡»ä¸‹æ–¹æŒ‰é’®æŸ¥çœ‹å¯¹åº”æ’åçš„åœ°å€è¯¦æƒ…</i>\n"
    msg += f"ğŸ“Š <i>æ‰€æœ‰ç™¾åˆ†æ¯”å‡ä¸ºå ä»£å¸æµé€šé‡çš„æ¯”ä¾‹</i>\n"
    
    return msg
